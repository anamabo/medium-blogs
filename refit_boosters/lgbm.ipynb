{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e80085-11ce-4528-a5bd-54affe6d942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, average_precision_score, roc_curve\n",
    "import optuna\n",
    "from typing import Any, Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fdd9bd-078f-48d8-8479-af995a2fd987",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.read_parquet('./data/cleaned/heart_2022.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "881a7929-8289-4fae-b3f9-56cc16625314",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'HadHeartAttack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef282ac4-275c-42fc-9191-db510ba641c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_validation_test_sets(\n",
    "    X: pd.DataFrame, y: pd.Series\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split the dataset into training, valiidation and testing sets.\n",
    "    Args:\n",
    "        X (pd.DataFrame): Feature matrix.\n",
    "        y (pd.Series): Labels.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "    Returns:\n",
    "        Tuple: \n",
    "        X_train, y_train: Training set (60%)\n",
    "        X_val, y_val: Validation set (20%)\n",
    "        X_test, y_test: Test set (20%)\n",
    "    \"\"\"\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "    return X_train, X_val, X_test, y_train.values, y_val.values, y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c72359-caf4-46bd-b4a1-718e2799e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(full_dataset.select_dtypes(include=['category']).columns)\n",
    "X = full_dataset[full_dataset.columns[full_dataset.columns != target]]\n",
    "y = full_dataset[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328ca3e4-f22a-4fcb-b7d3-c613afb56eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = create_train_validation_test_sets(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6dcd5fa-bc31-40be-bde0-c86f22a417d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    X_train: pd.DataFrame, y_train: np.ndarray, categorical_features: list[str]\n",
    ") -> lgb.LGBMClassifier:\n",
    "    \"\"\"\n",
    "    Train a LightGBM classifier.\n",
    "    \"\"\"\n",
    "    lgbm = lgb.LGBMClassifier(objective=\"binary\", metric=\"binary_logloss\", importance_type=\"split\", is_unbalance=True, random_state = 42)\n",
    "    lgbm.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        feature_name=X_train.columns.to_list(),\n",
    "        categorical_feature=categorical_features,\n",
    "        eval_metric=\"binary_logloss\"\n",
    "    )\n",
    "    return lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99ba6d8-19a3-4432-a30b-20774cf800cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_model(\n",
    "    X_train: pd.DataFrame, y_train: np.ndarray, categorical_features: list[str], init_model: lgb.LGBMClassifier\n",
    ") -> lgb.LGBMClassifier:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    lgbm_refit = lgb.LGBMClassifier(objective=\"binary\", metric=\"binary_logloss\", importance_type=\"split\", is_unbalance=True, random_state = 42)\n",
    "    lgbm_refit.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        feature_name=X_train.columns.to_list(),\n",
    "        categorical_feature=categorical_features,\n",
    "        eval_metric=\"binary_logloss\",\n",
    "        init_model=init_model\n",
    "    )\n",
    "    return lgbm_refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dbe5ab3-b8aa-4f90-a7cc-cd6679595d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(predicted_y: np.ndarray, y_true: np.ndarray) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate classification performance with various metrics.\n",
    "\n",
    "    Args:\n",
    "        predicted_y (np.ndarray): Predicted target\n",
    "        y_true (np.ndarray): Ground truth binary labels (bool).\n",
    "    Returns:\n",
    "        dict: A dictionary with metrics\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, predicted_y)\n",
    "    metrics = {\n",
    "        # \"log_loss\": metrics.log_loss(y, predictions_prob),\n",
    "        # \"brier_score\": metrics.brier_score_loss(y, predictions_prob),\n",
    "        \"auc\": auc(fpr, tpr),\n",
    "        \"pr_auc\": average_precision_score(y_true, predicted_y)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61022fac-ce48-4969-bda9-6afcd7d4a942",
   "metadata": {},
   "source": [
    "# Experiment 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae48b350-c89f-4346-9897-e9646493efde",
   "metadata": {},
   "source": [
    "## Part 1:\n",
    "1. Train model using train + validation sets.\n",
    "2. Evaluate using test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a43d61a-cbee-4ca5-8ff5-f2e73e11286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10748, number of negative: 186069\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 834\n",
      "[LightGBM] [Info] Number of data points in the train set: 196817, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.054609 -> initscore=-2.851398\n",
      "[LightGBM] [Info] Start training from score -2.851398\n"
     ]
    }
   ],
   "source": [
    "lgbm = train_model(X_train=pd.concat([X_train, X_val]), y_train=np.concatenate([y_train, y_val]), categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5dbbdaa-0395-4efc-ad76-979a12aa8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target_train_val= lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eec6ec7-d03d-453a-8cdf-76beab6f64d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7977225458407695, 'pr_auc': 0.1730128499227533}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(predicted_target_train_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1c055-ff3b-4a23-953a-ded1475f39ad",
   "metadata": {},
   "source": [
    "## Part 2:\n",
    "1. Train model using train set\n",
    "2. retrain the model using validation sets.\n",
    "3. Evaluate using test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d3e52ec-f5b5-4377-b4a7-cb764c877beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8061, number of negative: 139552\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 827\n",
      "[LightGBM] [Info] Number of data points in the train set: 147613, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.054609 -> initscore=-2.851400\n",
      "[LightGBM] [Info] Start training from score -2.851400\n"
     ]
    }
   ],
   "source": [
    "lgbm_train = train_model(X_train=X_train, y_train=y_train, categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21fb0648-fb19-47be-ab1f-94930cc33d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target_train = lgbm_train.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd3e7c0-a304-4c9e-b032-187e1056a764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7983648253587101, 'pr_auc': 0.17749637824737013}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(predicted_target_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0a77664-99e6-4998-a0e9-a0122c2ae95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2687, number of negative: 46517\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 795\n",
      "[LightGBM] [Info] Number of data points in the train set: 49204, number of used features: 38\n"
     ]
    }
   ],
   "source": [
    "lgbm_refit_val = refit_model(X_train=X_val, y_train=y_val, categorical_features=categorical_features, init_model=lgbm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d44789f9-7327-42c8-b52f-1872a14a1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target_refit_val= lgbm_refit_val.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48f6f77a-2983-49b4-9e01-24c2e9779454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7877388759221192, 'pr_auc': 0.18145183399216608}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(predicted_target_refit_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cc5b9-a0ba-4c62-8150-d9b50b3c6e12",
   "metadata": {},
   "source": [
    "# Experiment 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a4ded-cf72-4969-b180-7c3574935111",
   "metadata": {},
   "source": [
    "Use lightGBM and Optuna.\n",
    "\n",
    "1. Train model using train set and do hyperparameter tuning using Optuna.\n",
    "2. Evaluate the model using the test set.\n",
    "3. Refit the model using the validation set.\n",
    "4. Evaluate the refitted model using the test set.\n",
    "5. Compare the evaluations before and after refit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbd6ef-733d-47ff-8c40-eb7ce01939fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, y_train, X_test, y_test, categorical_features):\n",
    "    \"\"\"\n",
    "    Objective function for optuna hyperparameter tunning\n",
    "    \"\"\"\n",
    "    params_range = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"importance_type\": \"split\",\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.05),\n",
    "    }\n",
    "\n",
    "    lgbm = lgb.LGBMClassifier(**params_range)\n",
    "\n",
    "    lgbm.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        feature_name=X_train.columns.to_list(),\n",
    "        categorical_feature=categorical_features,\n",
    "        eval_metric=\"binary_logloss\",\n",
    "    )\n",
    "    predictions_prob = lgbm.predict_proba(X_test)[:, 1]\n",
    "    brier_score = sklearn.metrics.brier_score_loss(y_test, predictions_prob, sample_weight=None)\n",
    "    return brier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f4cb29-c0f6-49aa-b9b9-da60190e0ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
