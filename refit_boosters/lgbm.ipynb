{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7e80085-11ce-4528-a5bd-54affe6d942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from typing import Any, Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fdd9bd-078f-48d8-8479-af995a2fd987",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.read_parquet('./data/preprocess_data/heart_2022.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "881a7929-8289-4fae-b3f9-56cc16625314",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'HadHeartAttack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef282ac4-275c-42fc-9191-db510ba641c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_validation_test_sets(\n",
    "    X: pd.DataFrame, y: pd.Series\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split the dataset into training, valiidation and testing sets.\n",
    "    Args:\n",
    "        X (pd.DataFrame): Feature matrix.\n",
    "        y (pd.Series): Labels.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "    Returns:\n",
    "        Tuple: \n",
    "        X_train, y_train: Training set (60%)\n",
    "        X_val, y_val: Validation set (20%)\n",
    "        X_test, y_test: Test set (20%)\n",
    "    \"\"\"\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "    return X_train, X_val, X_test, y_train.values, y_val.values, y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1c72359-caf4-46bd-b4a1-718e2799e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_dataset[full_dataset.columns[full_dataset.columns != target]]\n",
    "y = full_dataset[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "328ca3e4-f22a-4fcb-b7d3-c613afb56eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = create_train_validation_test_sets(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6dcd5fa-bc31-40be-bde0-c86f22a417d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    X_train: pd.DataFrame, y_train: np.ndarray, categorical_features: list[str]\n",
    ") -> lgb.LGBMClassifier:\n",
    "    \"\"\"\n",
    "    Train a LightGBM classifier.\n",
    "    \"\"\"\n",
    "    lgbm = lgb.LGBMClassifier(objective=\"binary\", metric=\"binary_logloss\", importance_type=\"split\", is_unbalance=True)\n",
    "    lgbm.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        feature_name=X_train.columns.to_list(),\n",
    "        categorical_feature=categorical_features,\n",
    "        eval_metric=\"binary_logloss\"\n",
    "    )\n",
    "    return lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7dbe5ab3-b8aa-4f90-a7cc-cd6679595d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(predicted_prob: np.ndarray, y_true: np.ndarray) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate classification performance with various metrics.\n",
    "\n",
    "    Args:\n",
    "        predicted_prob (np.ndarray): Predicted probabilities\n",
    "        y_tue (np.ndarray): Ground truth binary labels (bool).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with metrics\n",
    "    \"\"\"\n",
    "    prediction_threshold = float(os.getenv(\"PREDICTION_THRESHOLD\", \"0.05\"))\n",
    "    predictions_binary = (predictions_prob > prediction_threshold).astype(int)\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y, predictions_prob)\n",
    "    metrics = {\n",
    "        \"log_loss\": metrics.log_loss(y, predictions_prob),\n",
    "        \"brier_score\": metrics.brier_score_loss(y, predictions_prob),\n",
    "        \"auc\": metrics.auc(fpr, tpr)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61022fac-ce48-4969-bda9-6afcd7d4a942",
   "metadata": {},
   "source": [
    "# Experiment 1:\n",
    "Use lightGBM.\n",
    "\n",
    "1. Train model using train + validation sets.\n",
    "2. Evaluate using test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7578b503-5f45-4e0b-a964-636c1a41f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(full_dataset.select_dtypes(include=['category']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a43d61a-cbee-4ca5-8ff5-f2e73e11286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10748, number of negative: 186069\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 834\n",
      "[LightGBM] [Info] Number of data points in the train set: 196817, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.054609 -> initscore=-2.851398\n",
      "[LightGBM] [Info] Start training from score -2.851398\n"
     ]
    }
   ],
   "source": [
    "lgbm = train_model(X_train=pd.concat([X_train, X_val]), y_train=np.concatenate([y_train, y_val]), categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655399f2-4823-4601-8e2c-37e98adf14b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40339ea5-67f0-4add-95d2-508a556eeea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ed68c-11f7-47b7-9542-6f4e05f99da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c6a46-e530-4d77-ab82-db815c8e1fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b35cc5b9-a0ba-4c62-8150-d9b50b3c6e12",
   "metadata": {},
   "source": [
    "# Experiment 3:\n",
    "Use lightGBM and Optuna.\n",
    "\n",
    "1. Train model using train set and do hyperparameter tuning using Optuna.\n",
    "2. Evaluate the model using the test set.\n",
    "3. Refit the model using the validation set.\n",
    "4. Evaluate the refitted model using the test set.\n",
    "5. Compare the evaluations before and after refit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbd6ef-733d-47ff-8c40-eb7ce01939fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, y_train, X_test, y_test, categorical_features):\n",
    "    \"\"\"\n",
    "    Objective function for optuna hyperparameter tunning\n",
    "    \"\"\"\n",
    "    params_range = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"importance_type\": \"split\",\n",
    "        \"verbosity\": -1,\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.05),\n",
    "    }\n",
    "\n",
    "    lgbm = lgb.LGBMClassifier(**params_range)\n",
    "\n",
    "    lgbm.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        feature_name=X_train.columns.to_list(),\n",
    "        categorical_feature=categorical_features,\n",
    "        eval_metric=\"binary_logloss\",\n",
    "    )\n",
    "    predictions_prob = lgbm.predict_proba(X_test)[:, 1]\n",
    "    brier_score = sklearn.metrics.brier_score_loss(y_test, predictions_prob, sample_weight=None)\n",
    "    return brier_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
